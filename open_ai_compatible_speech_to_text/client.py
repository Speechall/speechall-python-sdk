# This file was auto-generated by Fern from our API Definition.

import typing
from ..core.client_wrapper import SyncClientWrapper
from .. import core
from ..types.transcription_model_identifier import TranscriptionModelIdentifier
from ..types.open_ai_audio_response_format import OpenAiAudioResponseFormat
from .types.openai_compatible_create_transcription_request_timestamp_granularities_item import (
    OpenaiCompatibleCreateTranscriptionRequestTimestampGranularitiesItem,
)
from ..core.request_options import RequestOptions
from .types.openai_compatible_create_transcription_response import OpenaiCompatibleCreateTranscriptionResponse
from ..core.pydantic_utilities import parse_obj_as
from ..errors.bad_request_error import BadRequestError
from ..types.error_response import ErrorResponse
from ..errors.unauthorized_error import UnauthorizedError
from ..errors.payment_required_error import PaymentRequiredError
from ..errors.not_found_error import NotFoundError
from ..errors.too_many_requests_error import TooManyRequestsError
from ..errors.internal_server_error import InternalServerError
from ..errors.service_unavailable_error import ServiceUnavailableError
from ..errors.gateway_timeout_error import GatewayTimeoutError
from json.decoder import JSONDecodeError
from ..core.api_error import ApiError
from .types.openai_compatible_create_translation_request_model import OpenaiCompatibleCreateTranslationRequestModel
from .types.openai_compatible_create_translation_response import OpenaiCompatibleCreateTranslationResponse
from ..core.client_wrapper import AsyncClientWrapper

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class OpenAiCompatibleSpeechToTextClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._client_wrapper = client_wrapper

    def openai_compatible_create_transcription(
        self,
        *,
        file: core.File,
        model: TranscriptionModelIdentifier,
        language: typing.Optional[str] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        response_format: typing.Optional[OpenAiAudioResponseFormat] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        timestamp_granularities: typing.Optional[
            typing.List[OpenaiCompatibleCreateTranscriptionRequestTimestampGranularitiesItem]
        ] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> OpenaiCompatibleCreateTranscriptionResponse:
        """
        Mimics the OpenAI `/audio/transcriptions` endpoint. Accepts audio file uploads via `multipart/form-data`.
        Allows specifying model, language, prompt, response format, temperature, and timestamp granularity similar to OpenAI.
        Note: The `model` parameter should use Speechall's `provider.model` format.

        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        model : TranscriptionModelIdentifier
            The Speechall model identifier (`provider.model`) to use for transcription.

        language : typing.Optional[str]
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

        prompt : typing.Optional[str]
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.

        response_format : typing.Optional[OpenAiAudioResponseFormat]
            The desired format for the transcription output. Defaults to `json`.

        temperature : typing.Optional[float]
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

        timestamp_granularities : typing.Optional[typing.List[OpenaiCompatibleCreateTranscriptionRequestTimestampGranularitiesItem]]
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        OpenaiCompatibleCreateTranscriptionResponse
            Transcription successful. The response body format depends on the `response_format` parameter specified in the request:
            - `json`: Returns `OpenAI_CreateTranscriptionResponseJson`.
            - `verbose_json`: Returns `OpenAI_CreateTranscriptionResponseVerboseJson` with detailed segments and optional word timestamps.
            - `text`, `srt`, `vtt`: Returns the transcription as plain text in the specified format.

        Examples
        --------
        from speechall import Speechall

        client = Speechall(
            token="YOUR_TOKEN",
        )
        client.open_ai_compatible_speech_to_text.openai_compatible_create_transcription(
            model="amazon.transcribe",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "openai-compatible/audio/transcriptions",
            method="POST",
            data={
                "model": model,
                "language": language,
                "prompt": prompt,
                "response_format": response_format,
                "temperature": temperature,
                "timestamp_granularities[]": timestamp_granularities,
            },
            files={
                "file": core.with_content_type(file=file, default_content_type="audio/*"),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    OpenaiCompatibleCreateTranscriptionResponse,
                    parse_obj_as(
                        type_=OpenaiCompatibleCreateTranscriptionResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 401:
                raise UnauthorizedError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 503:
                raise ServiceUnavailableError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 504:
                raise GatewayTimeoutError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    def openai_compatible_create_translation(
        self,
        *,
        file: core.File,
        model: OpenaiCompatibleCreateTranslationRequestModel,
        prompt: typing.Optional[str] = OMIT,
        response_format: typing.Optional[OpenAiAudioResponseFormat] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> OpenaiCompatibleCreateTranslationResponse:
        """
        Mimics the OpenAI `/audio/translations` endpoint. Accepts audio file uploads via `multipart/form-data` and translates the speech into English text.
        Allows specifying model, prompt, response format, and temperature similar to OpenAI.
        Note: The `model` parameter should use Speechall's `provider.model` format (ensure the selected model supports translation).

        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        model : OpenaiCompatibleCreateTranslationRequestModel
            ID of the model to use. It follows the naming convention provider/model-name

        prompt : typing.Optional[str]
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.

        response_format : typing.Optional[OpenAiAudioResponseFormat]
            The desired format for the translation output. Defaults to `json`.

        temperature : typing.Optional[float]
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        OpenaiCompatibleCreateTranslationResponse
            Translation successful. The output is always English text. The response body format depends on the `response_format` parameter:
            - `json`: Returns `OpenAI_CreateTranslationResponseJson`.
            - `verbose_json`: Returns `OpenAI_CreateTranslationResponseVerboseJson` with detailed segments.
            - `text`, `srt`, `vtt`: Returns the translated English text as plain text in the specified format.

        Examples
        --------
        from speechall import Speechall

        client = Speechall(
            token="YOUR_TOKEN",
        )
        client.open_ai_compatible_speech_to_text.openai_compatible_create_translation(
            model="model",
        )
        """
        _response = self._client_wrapper.httpx_client.request(
            "openai-compatible/audio/translations",
            method="POST",
            data={
                "model": model,
                "prompt": prompt,
                "response_format": response_format,
                "temperature": temperature,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    OpenaiCompatibleCreateTranslationResponse,
                    parse_obj_as(
                        type_=OpenaiCompatibleCreateTranslationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 401:
                raise UnauthorizedError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 503:
                raise ServiceUnavailableError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 504:
                raise GatewayTimeoutError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)


class AsyncOpenAiCompatibleSpeechToTextClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._client_wrapper = client_wrapper

    async def openai_compatible_create_transcription(
        self,
        *,
        file: core.File,
        model: TranscriptionModelIdentifier,
        language: typing.Optional[str] = OMIT,
        prompt: typing.Optional[str] = OMIT,
        response_format: typing.Optional[OpenAiAudioResponseFormat] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        timestamp_granularities: typing.Optional[
            typing.List[OpenaiCompatibleCreateTranscriptionRequestTimestampGranularitiesItem]
        ] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> OpenaiCompatibleCreateTranscriptionResponse:
        """
        Mimics the OpenAI `/audio/transcriptions` endpoint. Accepts audio file uploads via `multipart/form-data`.
        Allows specifying model, language, prompt, response format, temperature, and timestamp granularity similar to OpenAI.
        Note: The `model` parameter should use Speechall's `provider.model` format.

        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        model : TranscriptionModelIdentifier
            The Speechall model identifier (`provider.model`) to use for transcription.

        language : typing.Optional[str]
            The language of the input audio. Supplying the input language in [ISO-639-1](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes) format will improve accuracy and latency.

        prompt : typing.Optional[str]
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should match the audio language.

        response_format : typing.Optional[OpenAiAudioResponseFormat]
            The desired format for the transcription output. Defaults to `json`.

        temperature : typing.Optional[float]
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

        timestamp_granularities : typing.Optional[typing.List[OpenaiCompatibleCreateTranscriptionRequestTimestampGranularitiesItem]]
            The timestamp granularities to populate for this transcription. `response_format` must be set `verbose_json` to use timestamp granularities. Either or both of these options are supported: `word`, or `segment`. Note: There is no additional latency for segment timestamps, but generating word timestamps incurs additional latency.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        OpenaiCompatibleCreateTranscriptionResponse
            Transcription successful. The response body format depends on the `response_format` parameter specified in the request:
            - `json`: Returns `OpenAI_CreateTranscriptionResponseJson`.
            - `verbose_json`: Returns `OpenAI_CreateTranscriptionResponseVerboseJson` with detailed segments and optional word timestamps.
            - `text`, `srt`, `vtt`: Returns the transcription as plain text in the specified format.

        Examples
        --------
        import asyncio

        from speechall import AsyncSpeechall

        client = AsyncSpeechall(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.open_ai_compatible_speech_to_text.openai_compatible_create_transcription(
                model="amazon.transcribe",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "openai-compatible/audio/transcriptions",
            method="POST",
            data={
                "model": model,
                "language": language,
                "prompt": prompt,
                "response_format": response_format,
                "temperature": temperature,
                "timestamp_granularities[]": timestamp_granularities,
            },
            files={
                "file": core.with_content_type(file=file, default_content_type="audio/*"),
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    OpenaiCompatibleCreateTranscriptionResponse,
                    parse_obj_as(
                        type_=OpenaiCompatibleCreateTranscriptionResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 401:
                raise UnauthorizedError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 503:
                raise ServiceUnavailableError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 504:
                raise GatewayTimeoutError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)

    async def openai_compatible_create_translation(
        self,
        *,
        file: core.File,
        model: OpenaiCompatibleCreateTranslationRequestModel,
        prompt: typing.Optional[str] = OMIT,
        response_format: typing.Optional[OpenAiAudioResponseFormat] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> OpenaiCompatibleCreateTranslationResponse:
        """
        Mimics the OpenAI `/audio/translations` endpoint. Accepts audio file uploads via `multipart/form-data` and translates the speech into English text.
        Allows specifying model, prompt, response format, and temperature similar to OpenAI.
        Note: The `model` parameter should use Speechall's `provider.model` format (ensure the selected model supports translation).

        Parameters
        ----------
        file : core.File
            See core.File for more documentation

        model : OpenaiCompatibleCreateTranslationRequestModel
            ID of the model to use. It follows the naming convention provider/model-name

        prompt : typing.Optional[str]
            An optional text to guide the model's style or continue a previous audio segment. The [prompt](/docs/guides/speech-to-text/prompting) should be in English.

        response_format : typing.Optional[OpenAiAudioResponseFormat]
            The desired format for the translation output. Defaults to `json`.

        temperature : typing.Optional[float]
            The sampling temperature, between 0 and 1. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. If set to 0, the model will use [log probability](https://en.wikipedia.org/wiki/Log_probability) to automatically increase the temperature until certain thresholds are hit.

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        OpenaiCompatibleCreateTranslationResponse
            Translation successful. The output is always English text. The response body format depends on the `response_format` parameter:
            - `json`: Returns `OpenAI_CreateTranslationResponseJson`.
            - `verbose_json`: Returns `OpenAI_CreateTranslationResponseVerboseJson` with detailed segments.
            - `text`, `srt`, `vtt`: Returns the translated English text as plain text in the specified format.

        Examples
        --------
        import asyncio

        from speechall import AsyncSpeechall

        client = AsyncSpeechall(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.open_ai_compatible_speech_to_text.openai_compatible_create_translation(
                model="model",
            )


        asyncio.run(main())
        """
        _response = await self._client_wrapper.httpx_client.request(
            "openai-compatible/audio/translations",
            method="POST",
            data={
                "model": model,
                "prompt": prompt,
                "response_format": response_format,
                "temperature": temperature,
            },
            files={
                "file": file,
            },
            request_options=request_options,
            omit=OMIT,
        )
        try:
            if 200 <= _response.status_code < 300:
                return typing.cast(
                    OpenaiCompatibleCreateTranslationResponse,
                    parse_obj_as(
                        type_=OpenaiCompatibleCreateTranslationResponse,  # type: ignore
                        object_=_response.json(),
                    ),
                )
            if _response.status_code == 400:
                raise BadRequestError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 401:
                raise UnauthorizedError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 402:
                raise PaymentRequiredError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 404:
                raise NotFoundError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 429:
                raise TooManyRequestsError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 500:
                raise InternalServerError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 503:
                raise ServiceUnavailableError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            if _response.status_code == 504:
                raise GatewayTimeoutError(
                    typing.cast(
                        ErrorResponse,
                        parse_obj_as(
                            type_=ErrorResponse,  # type: ignore
                            object_=_response.json(),
                        ),
                    )
                )
            _response_json = _response.json()
        except JSONDecodeError:
            raise ApiError(status_code=_response.status_code, body=_response.text)
        raise ApiError(status_code=_response.status_code, body=_response_json)
